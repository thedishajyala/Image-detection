{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4e3fa4d7-ccda-4a98-8503-c19f072b74c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nisht\\AppData\\Local\\Temp\\ipykernel_29216\\2424267059.py:30: FutureWarning: factorize with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  labels = np.array(pd.factorize(labels)[0])  # Convert labels to integers\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Dataset parameters\n",
    "dataset_path = 'C:/Users/nisht/Project/ISL_Dataset'  # Replace with your dataset path\n",
    "IMG_SIZE = 64\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Data loading and preprocessing\n",
    "def load_data(dataset_path, img_size=IMG_SIZE):\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for label_dir in os.listdir(dataset_path):\n",
    "        label_path = os.path.join(dataset_path, label_dir)\n",
    "        if os.path.isdir(label_path):\n",
    "            for img_file in os.listdir(label_path):\n",
    "                img_path = os.path.join(label_path, img_file)\n",
    "                img = cv2.imread(img_path)\n",
    "                img = cv2.resize(img, (img_size, img_size))  # Resize image\n",
    "                images.append(img)\n",
    "                labels.append(label_dir)\n",
    "    \n",
    "    images = np.array(images) / 255.0  # Normalize images\n",
    "    labels = np.array(pd.factorize(labels)[0])  # Convert labels to integers\n",
    "    return images, labels\n",
    "\n",
    "images, labels = load_data(dataset_path)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "train_generator = train_datagen.flow(X_train, y_train, batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51627772-7597-4f69-8e86-449b7bd82041",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def build_cnn():\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(len(np.unique(labels)), activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Train CNN model\n",
    "cnn_model = build_cnn()\n",
    "cnn_model.fit(train_generator, epochs=20, validation_data=(X_test, y_test))\n",
    "y_pred_cnn = np.argmax(cnn_model.predict(X_test), axis=1)\n",
    "print(classification_report(y_test, y_pred_cnn))\n",
    "cnn_model.save('cnn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d27af7d-b921-4a04-a8db-c7503c49ec27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "\n",
    "def build_vgg16():\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    model = Sequential([\n",
    "        base_model,\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(len(np.unique(labels)), activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Train VGG16 model\n",
    "vgg16_model = build_vgg16()\n",
    "vgg16_model.fit(train_generator, epochs=20, validation_data=(X_test, y_test))\n",
    "y_pred_vgg16 = np.argmax(vgg16_model.predict(X_test), axis=1)\n",
    "print(classification_report(y_test, y_pred_vgg16))\n",
    "vgg16_model.save('vgg16_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec71e85-6ca7-45d4-87c3-748eff03b9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "\n",
    "def build_resnet50():\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    model = Sequential([\n",
    "        base_model,\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(len(np.unique(labels)), activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Train ResNet50 model\n",
    "resnet50_model = build_resnet50()\n",
    "resnet50_model.fit(train_generator, epochs=20, validation_data=(X_test, y_test))\n",
    "y_pred_resnet50 = np.argmax(resnet50_model.predict(X_test), axis=1)\n",
    "print(classification_report(y_test, y_pred_resnet50))\n",
    "resnet50_model.save('resnet50_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcac792e-8c9e-4c5c-85ed-b2b3b70d9a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import ConvLSTM2D, BatchNormalization, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.layers import TimeDistributed, Conv2D, MaxPooling2D\n",
    "import numpy as np\n",
    "\n",
    "# Preparing the data for ConvLSTM\n",
    "# ConvLSTM expects a 5D tensor: (samples, timesteps, rows, cols, channels)\n",
    "# Here, we simulate \"timesteps\" by adding a dummy dimension\n",
    "\n",
    "def prepare_data_for_convlstm(images, timesteps=1):\n",
    "    # Adding a time dimension for ConvLSTM (assuming static images treated as one timestep each)\n",
    "    images = np.expand_dims(images, axis=1)  # Shape: (samples, timesteps, rows, cols, channels)\n",
    "    return images\n",
    "\n",
    "X_train_lstm = prepare_data_for_convlstm(X_train)\n",
    "X_test_lstm = prepare_data_for_convlstm(X_test)\n",
    "\n",
    "# Model Definition\n",
    "def build_convlstm(input_shape):\n",
    "    model = Sequential([\n",
    "        # ConvLSTM layer\n",
    "        ConvLSTM2D(filters=64, kernel_size=(3, 3), activation='relu', input_shape=input_shape, return_sequences=False),\n",
    "        BatchNormalization(),\n",
    "        \n",
    "        # Fully connected layers\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(len(np.unique(labels)), activation='softmax')  # Output layer with softmax\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Build the model\n",
    "input_shape = (X_train_lstm.shape[1], IMG_SIZE, IMG_SIZE, 3)  # (timesteps, rows, cols, channels)\n",
    "convlstm_model = build_convlstm(input_shape)\n",
    "\n",
    "# Train the model\n",
    "history = convlstm_model.fit(\n",
    "    X_train_lstm, y_train,\n",
    "    epochs=20,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=(X_test_lstm, y_test)\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_lstm = np.argmax(convlstm_model.predict(X_test_lstm), axis=1)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_lstm))\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred_lstm))\n",
    "\n",
    "# Save the model\n",
    "convlstm_model.save('convlstm_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f715b804-0230-4659-937c-76c0922f4759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarizing model performance\n",
    "model_reports = {\n",
    "    \"CNN\": classification_report(y_test, y_pred_cnn, output_dict=True),\n",
    "    \"VGG16\": classification_report(y_test, y_pred_vgg16, output_dict=True),\n",
    "    \"ResNet50\": classification_report(y_test, y_pred_resnet50, output_dict=True),\n",
    "    \"ConvLSTM\": classification_report(y_test, y_pred_lstm, output_dict=True),\n",
    "}\n",
    "\n",
    "best_model_name = max(model_reports, key=lambda x: model_reports[x]['accuracy'])\n",
    "print(f\"The best model is {best_model_name}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
